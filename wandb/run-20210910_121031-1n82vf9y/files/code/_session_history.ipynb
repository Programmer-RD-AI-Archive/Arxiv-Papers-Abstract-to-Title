{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f281a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from torch.nn import *\n",
    "from torch.optim import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch,torchvision\n",
    "import random\n",
    "from tqdm import *\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1222d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    return nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6afe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$', '100']"
     ]
    }
   ],
   "source": [
    "tokenize('$100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c133c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    return stemmer.stem(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff8500e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'organ'"
     ]
    }
   ],
   "source": [
    "stem('ORGANIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e08e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(tokenized_words,all_words):\n",
    "    tokenized_words = [stem(w) for w in tokenized_words]\n",
    "    bag = np.zeros(len(all_words))\n",
    "    for idx,w in enumerate(all_words):\n",
    "        if w in tokenized_words:\n",
    "            bag[idx] = 1.0\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ccacee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([0., 1.])"
     ]
    }
   ],
   "source": [
    "bag_of_words(['hi'],['how','hi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff13ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb6bddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Abstract']\n",
    "y = data['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d56a9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'  Discourse structures are beneficial for various NLP tasks such as dialogue\\nunderstanding, question answering, sentiment analysis, and so on. This paper\\npresents a deep sequential model for parsing discourse dependency structures of\\nmulti-party dialogues. The proposed model aims to construct a discourse\\ndependency tree by predicting dependency relations and constructing the\\ndiscourse structure jointly and alternately. It makes a sequential scan of the\\nElementary Discourse Units (EDUs) in a dialogue. For each EDU, the model\\ndecides to which previous EDU the current one should link and what the\\ncorresponding relation type is. The predicted link and relation type are then\\nused to build the discourse structure incrementally with a structured encoder.\\nDuring link prediction and relation classification, the model utilizes not only\\nlocal information that represents the concerned EDUs, but also global\\ninformation that encodes the EDU sequence and the discourse structure that is\\nalready built at the current step. Experiments show that the proposed model\\noutperforms all the state-of-the-art baselines.\\n'"
     ]
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cd9b09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A Deep Sequential Model for Discourse Parsing on Multi-Party Dialogues'"
     ]
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f15aebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_X = []\n",
    "all_words_y = []\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b5c6105",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X_batch,y_batch in tqdm(zip(X,y)):\n",
    "    X_batch = tokenize(X_batch)\n",
    "    y_batch = tokenize(y_batch)\n",
    "    new_X = []\n",
    "    new_y = []\n",
    "    for Xb in X_batch:\n",
    "        new_X.append(stem(Xb))\n",
    "    for yb in y_batch:\n",
    "        new_y.append(stem(yb))\n",
    "    all_words_X.extend(new_X)\n",
    "    all_words_y.extend(new_y)\n",
    "    data.append([new_X,new_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "710fd83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78c44f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_X = sorted(set(all_words_X))\n",
    "all_words_y = sorted(set(all_words_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebfc530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Xb,yb in tqdm(data):\n",
    "    X.append(bag_of_words(Xb,all_words_X))\n",
    "    y.append(bag_of_words(yb,all_words_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94103955",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_X = sorted(set(all_words_X))\n",
    "all_words_y = sorted(set(all_words_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1f6f91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model,X,y):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    preds = model(X)\n",
    "    for pred,y_batch in zip(preds,y):\n",
    "        if pred == y_batch:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    acc = round(correct/total,3)*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f355a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = ReLU()\n",
    "        self.iters = 10\n",
    "        self.linear1 = Linear(len(all_words_X),1024)\n",
    "        self.linear2 = Linear(1024,1024)\n",
    "        self.output = Linear(1024,len(all_words_y))\n",
    "    \n",
    "    def forward(self,X):\n",
    "        preds = self.activation(self.linear1(X))\n",
    "        for _ in range(self.iters):\n",
    "            preds = self.activation(self.linear2(preds))\n",
    "        preds = self.output(preds)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8618d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "958a8e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5851333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f6d3592",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fae20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1027a7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'Arxiv-Papers-Abstract-to-Title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50b643e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for idx in range(0,len(X),batch_size):\n",
    "        X_batch = X[idx:idx+batch_size].to(device).float()\n",
    "        y_batch = y[idx:idx+batch_size].to(device).float()\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    wandb.log({'Loss':loss.item()})\n",
    "    wandb.log({'Accuracy':accuracy(model,X,y)})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de4ecd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fb3e7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.1<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">baseline</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ranuga-d/Arxiv-Papers-Abstract-to-Title\" target=\"_blank\">https://wandb.ai/ranuga-d/Arxiv-Papers-Abstract-to-Title</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ranuga-d/Arxiv-Papers-Abstract-to-Title/runs/1n82vf9y\" target=\"_blank\">https://wandb.ai/ranuga-d/Arxiv-Papers-Abstract-to-Title/runs/1n82vf9y</a><br/>\n",
       "                Run data is saved locally in <code>/home/indika/Programming/Projects/Python/Artifical-Intelligence/PyTorch/NLP/Arxiv-Papers-Abstract-to-Title/wandb/run-20210910_121031-1n82vf9y</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for idx in range(0,len(X),batch_size):\n",
    "        X_batch = X[idx:idx+batch_size].to(device).float()\n",
    "        y_batch = y[idx:idx+batch_size].to(device).float()\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    wandb.log({'Loss':loss.item()})\n",
    "    wandb.log({'Accuracy':accuracy(model,X,y)})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a5d162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(np.array(X)).to(device).float()\n",
    "y = torch.from_numpy(np.array(y)).to(device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e348be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model,X,y):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    preds = model(X)\n",
    "    for pred,y_batch in zip(preds,y):\n",
    "        if pred == y_batch:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    acc = round(correct/total,3)*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a603d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = ReLU()\n",
    "        self.iters = 10\n",
    "        self.linear1 = Linear(len(all_words_X),1024)\n",
    "        self.linear2 = Linear(1024,1024)\n",
    "        self.output = Linear(1024,len(all_words_y))\n",
    "    \n",
    "    def forward(self,X):\n",
    "        preds = self.activation(self.linear1(X))\n",
    "        for _ in range(self.iters):\n",
    "            preds = self.activation(self.linear2(preds))\n",
    "        preds = self.output(preds)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f887e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "747c3191",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afd5eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6234c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f27981fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca01f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = 'Arxiv-Papers-Abstract-to-Title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1593aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1448df3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=PROJECT_NAME,name='baseline')\n",
    "for _ in tqdm(range(epochs)):\n",
    "    for idx in range(0,len(X),batch_size):\n",
    "        X_batch = X[idx:idx+batch_size].to(device).float()\n",
    "        y_batch = y[idx:idx+batch_size].to(device).float()\n",
    "        preds = model(X_batch)\n",
    "        loss = criterion(preds,y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    wandb.log({'Loss':loss.item()})\n",
    "    wandb.log({'Accuracy':accuracy(model,X,y)})\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
